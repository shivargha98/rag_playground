{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ec72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader,DirectoryLoader,PyPDFLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatGoogleGenerativeAI(model = 'gemini-2.0-flash',max_retries=2)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2') ##embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "181f9c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Documents loaded : 5\n",
      "Document number: 1\n",
      "Document data preview:\n",
      "ChatGPT and Conversational AI\n",
      "\n",
      "ChatGPT is one of the most widely known conversational AI models deve\n",
      "Document metadata:\n",
      "{'source': 'data\\\\chatgpt_conversational_ai.txt'}\n",
      "-------------------\n",
      "Document number: 2\n",
      "Document data preview:\n",
      "Convolutional Neural Networks (CNNs)\n",
      "\n",
      "Convolutional Neural Networks, or CNNs, are a class of deep le\n",
      "Document metadata:\n",
      "{'source': 'data\\\\convolutional_neural_networks.txt'}\n",
      "-------------------\n",
      "Document number: 3\n",
      "Document data preview:\n",
      "Google Gemini and the Rise of Multimodal AI\n",
      "\n",
      "Google Gemini represents a new generation of large-scal\n",
      "Document metadata:\n",
      "{'source': 'data\\\\google_gemini_multimodal_ai.txt'}\n",
      "-------------------\n",
      "Document number: 4\n",
      "Document data preview:\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "Machine Learning (ML) is a branch of artificial intelligence focused \n",
      "Document metadata:\n",
      "{'source': 'data\\\\machine_learning_fundamentals.txt'}\n",
      "-------------------\n",
      "Document number: 5\n",
      "Document data preview:\n",
      "Transformer Architecture\n",
      "\n",
      "The Transformer architecture revolutionized the field of natural language \n",
      "Document metadata:\n",
      "{'source': 'data\\\\transformer_architecture.txt'}\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "## Document/Directory Loader ##\n",
    "doc_loaders = DirectoryLoader(\n",
    "    path=\"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\":'utf-8'}\n",
    ")\n",
    "docs = doc_loaders.load()\n",
    "print(f\"Number Documents loaded : {len(docs)}\")\n",
    "for index,doc in enumerate(docs):\n",
    "    print(f\"Document number: {index+1}\")\n",
    "    print(f\"Document data preview:\\n{doc.page_content[0:100]}\")\n",
    "    print(f\"Document metadata:\\n{doc.metadata}\")\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks created: 22\n",
      "page_content='multiple sources.\n",
      "\n",
      "Unlike traditional LLMs that are text-only, Gemini can interpret visual inputs, perform cross-modal reasoning, and produce outputs that combine modalities. This makes it ideal for use cases like visual question answering, document analysis, or creative generation. It also integrates with Google Search, Workspace, and YouTube, enabling intelligent summarization, content generation, and recommendation systems.\n",
      "\n",
      "Technically, Gemini builds upon the Transformer architecture but' metadata={'source': 'data\\\\google_gemini_multimodal_ai.txt'} \n",
      "\n",
      "page_content='systems.\n",
      "\n",
      "Technically, Gemini builds upon the Transformer architecture but extends it with multimodal embeddings. These embeddings allow the model to represent different types of input (e.g., text and image) in a shared space. This unified understanding improves contextual grounding and factual accuracy. Gemini also benefits from large-scale reinforcement learning and extensive fine-tuning on proprietary and open datasets.\n",
      "\n",
      "The rise of multimodal AI marks an important shift from narrow,' metadata={'source': 'data\\\\google_gemini_multimodal_ai.txt'}\n"
     ]
    }
   ],
   "source": [
    "### text splitters ####\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 60\n",
    "    ,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "doc_chunks = text_splitter.split_documents(docs)\n",
    "print(f\"Total number of chunks created: {len(doc_chunks)}\")\n",
    "print(doc_chunks[10],\"\\n\")\n",
    "print(doc_chunks[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba975b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of vectors created in the vector store: 22\n",
      "Vector store saved to faiss_index directory\n"
     ]
    }
   ],
   "source": [
    "## create the FAISS vectorstore ##\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=doc_chunks,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "print(\"Total number of vectors created in the vector store:\",vector_store.index.ntotal)\n",
    "\n",
    "##save the faiss vector store##\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "print(\"Vector store saved to faiss_index directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c373f",
   "metadata": {},
   "source": [
    "### RAG PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9212ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    '''Creating a context from chunks'''\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are an intelligent assisstant, for question-answering tasks,\n",
    "Use the retrieved context given below to answer the question in a more streamlined way.\n",
    "Answer in only 3 sentences\n",
    "\n",
    "Context : {context}\n",
    "Question : {question}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "retreiver = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b649e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Transformer architecture, introduced in 2017, revolutionized NLP by replacing RNNs with a self-attention mechanism for efficient long-range dependency modeling. It processes input sequences in parallel, offering scalability and flexibility across various domains like vision and audio. Its capabilities have made it the foundation for generative AI, enabling machines to reason and create.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RAG CHAIN##\n",
    "rag_chain =( \n",
    "    {'context':retreiver | format_docs, \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm_model\n",
    "    | StrOutputParser()        \n",
    "    )\n",
    "rag_chain.invoke(\"Explain Transformer architecture in few sentences\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
