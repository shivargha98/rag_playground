{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe434688",
   "metadata": {},
   "source": [
    "## Autonomour RAG \n",
    "1. Query Decomposer/Planner Agent\n",
    "2. Tool Selector -> Retriever, Websearch \n",
    "3. Reflection \n",
    "4. Retry Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f27eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG_course\\rag_playground\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader,DirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage,BaseMessage,ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap,RunnableLambda,RunnableParallel,RunnablePassthrough\n",
    "from langchain.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.graph import END,START,StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm_model = ChatGoogleGenerativeAI(model = 'gemini-2.0-flash',max_retries=2)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',) ##embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa23629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs loaded: 5\n",
      "Document preview: AI in Healthcare: The New Frontier of Intelligent Medicine\n",
      "\n",
      "Artificial Intelligence (AI) is revolutionizing healthcare by enabling faster diagnosis, personalized treatment, and more efficient clinical\n",
      "Meta data preview: {'source': 'data\\\\ai_in_healthcare.txt'}\n",
      "\n",
      "\n",
      "Number of chunks created : 34\n",
      "Chunks preview (200 characters) : page_content='Agentic AI: The Evolution of Autonomous Intelligence\n",
      "\n",
      "Agentic AI represents the next major step in artificial intelligence—systems that not only respond intelligently but also act autonomously toward goals. Unlike traditional AI, which passively reacts to inputs, agentic AI operates through active reasoning, planning, and tool usage. These systems can decompose complex problems into smaller tasks, make decisions, and interact with external data sources to achieve objectives efficiently.' metadata={'source': 'data\\\\agentic_ai.txt'}\n",
      "\n",
      "\n",
      "Number of vectors stored : 34\n"
     ]
    }
   ],
   "source": [
    "docs = DirectoryLoader(\n",
    "    path = 'data',\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ").load()\n",
    "print(f\"Number of docs loaded: {len(docs)}\")\n",
    "print(f\"Document preview: {docs[2].page_content[:200]}\")\n",
    "print(f\"Meta data preview: {docs[2].metadata}\")\n",
    "\n",
    "\n",
    "\n",
    "doc_chunks = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    separators=[\"\\n\",\" \"]\n",
    ").split_documents(docs)\n",
    "print(\"\\n\")\n",
    "print(f\"Number of chunks created : {len(doc_chunks)}\")\n",
    "print(f\"Chunks preview (200 characters) : {doc_chunks[0]}\")\n",
    "\n",
    "### vector store ###\n",
    "persist_dir = \"./chromadb2\"\n",
    "vector_store1 = Chroma.from_documents(\n",
    "    documents=doc_chunks,\n",
    "    embedding= embedding_model,\n",
    "    collection_name='vec_store1',\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "retreiver1 = vector_store1.as_retriever(\n",
    "    search_type = 'mmr', search_kwargs = {'k':3})\n",
    "print(f\"Number of vectors stored : {vector_store1._collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3708983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded : 5\n",
      "Document Data preview : AI and Sustainability: Technology for a Greener Future\n",
      "\n",
      "Artificial Intelligence (AI) is emerging as a powerful tool for achieving sustainability goals. From optimizing energy consumption to monitoring deforestation, AI technologies enable data-driven environmental stewardship. When applied responsibly, AI can accelerate humanity’s transition to a low-carbon and resource-efficient future.\n",
      "\n",
      "In energ\n",
      "Meta data preview {'source': 'data3\\\\ai_and_sustainability.txt'}\n",
      "Number of chunks created : 21\n",
      "Chunk preview : AI and Sustainability: Technology for a Greener Future\n",
      "\n",
      "Artificial Intelligence (AI) is emerging as a powerful tool for achieving sustainability goals. From optimizing energy consumption to monitoring deforestation, AI technologies enable data-driven environmental stewardship. When applied responsibly, AI can accelerate humanity’s transition to a low-carbon and resource-efficient future.\n",
      "\n",
      "\n",
      "Number of vectors created : 21\n"
     ]
    }
   ],
   "source": [
    "docs2 = DirectoryLoader(\n",
    "    path=\"data3\",\n",
    "    glob = \"*.txt\",\n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ").load()\n",
    "\n",
    "print(f\"Number of documents loaded : {len(docs)}\")\n",
    "print(f\"Document Data preview : {docs2[0].page_content[:400]}\")\n",
    "print(f\"Meta data preview {docs2[0].metadata}\")\n",
    "\n",
    "\n",
    "doc_chunks2 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    separators=[\"\\n\",\" \"]\n",
    ").split_documents(docs2)\n",
    "\n",
    "print(f\"Number of chunks created : {len(doc_chunks2)}\")\n",
    "print(f\"Chunk preview : {doc_chunks2[0].page_content}\")\n",
    "\n",
    "persist_dir = './chromadb2'\n",
    "vector_store2 = Chroma.from_documents(\n",
    "    documents= doc_chunks2,\n",
    "    embedding = embedding_model,\n",
    "    collection_name='vec_store2',\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "retriever2 = vector_store2.as_retriever(\n",
    "            search_type = 'mmr',\n",
    "            search_kwargs = {'k':3}\n",
    ")\n",
    "print(f\"Number of vectors created : {vector_store2._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc9ca4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_ai_context_tool = create_retriever_tool(\n",
    "    retriever= retreiver1,\n",
    "    name='retriever_ai_context',\n",
    "    description='Vector store retriever for AI and AI use cases, Information on Machine & Deep Learning & Agentic AI'\n",
    ")\n",
    "\n",
    "retrieve_esg_context_tool = create_retriever_tool(\n",
    "    retriever= retriever2,\n",
    "    name = 'retrieve_esg_context',\n",
    "    description = 'Vector store retriever for ESG, AI & Sustainability,Greenwashing content'\n",
    ")\n",
    "\n",
    "## wikipedia ##\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper = WikipediaAPIWrapper())\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=ArxivAPIWrapper())\n",
    "## tavily search ##\n",
    "tavily_search_tool = TavilySearch(search_depth = 'advanced')\n",
    "\n",
    "tools = [retrieve_ai_context_tool,retrieve_esg_context_tool,wikipedia_tool,arxiv_tool,tavily_search_tool]\n",
    "llm_with_tools = llm_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a293076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1b875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df973d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac38b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6c5d56e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
