{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9636f2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG_course\\rag_playground\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader,DirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage,BaseMessage,ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap,RunnableLambda,RunnableParallel,RunnablePassthrough\n",
    "from langchain.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.graph import END,START,StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm_model = ChatGoogleGenerativeAI(model = 'gemini-2.0-flash',max_retries=2)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',) ##embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6783c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs loaded: 3\n",
      "Document preview: ﻿POLICY CONTRACT: SENTINEL 'SILVER' HEALTH SURAKSHA\n",
      "UIN: SHA-HLT-SLV-2025-V2 | CATEGORY: RETAIL INDEMNITY\n",
      "VERSION: 4.2 \n",
      "\n",
      "\n",
      "PREAMBLE\n",
      "WHEREAS the Insured named in the Schedule hereto has by a proposal an\n",
      "Meta data preview: {'source': 'policies\\\\silver_policy.txt'}\n",
      "\n",
      "\n",
      "Number of chunks created : 24\n",
      "Chunks preview (200 characters) : page_content='﻿POLICY CONTRACT: SENTINEL 'GOLD' PRIVILEGE\n",
      "UIN: SHA-HLT-GLD-2025-V1 | CATEGORY: COMPREHENSIVE\n",
      "VERSION: 2.1 \n",
      "\n",
      "\n",
      "SECTION 1: OPERATIVE CLAUSE\n",
      "The Company undertakes to indemnify the Insured Person against Medically Necessary expenses incurred for In-patient Care, Day Care Treatment, and Domiciliary Hospitalization, subject to the terms and sub-limits herein.\n",
      "\n",
      "\n",
      "SECTION 2: CORE BENEFITS\n",
      "2.1. ROOM RENT ELIGIBILITY\n",
      "    (a) The Policy covers expenses for a \"Single Private A/C Room\".' metadata={'source': 'policies\\\\gold_policy.txt'}\n",
      "\n",
      "\n",
      "Number of vectors stored : 24\n"
     ]
    }
   ],
   "source": [
    "docs = DirectoryLoader(\n",
    "    path = 'policies',\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ").load()\n",
    "print(f\"Number of docs loaded: {len(docs)}\")\n",
    "print(f\"Document preview: {docs[2].page_content[:200]}\")\n",
    "print(f\"Meta data preview: {docs[2].metadata}\")\n",
    "\n",
    "\n",
    "\n",
    "doc_chunks = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    separators=[\"\\n\",\" \"]\n",
    ").split_documents(docs)\n",
    "print(\"\\n\")\n",
    "print(f\"Number of chunks created : {len(doc_chunks)}\")\n",
    "print(f\"Chunks preview (200 characters) : {doc_chunks[0]}\")\n",
    "\n",
    "### vector store ###\n",
    "persist_dir = \"./chromadb\"\n",
    "vector_store1 = Chroma.from_documents(\n",
    "    documents=doc_chunks,\n",
    "    embedding= embedding_model,\n",
    "    collection_name='vec_store1',\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "retreiver1 = vector_store1.as_retriever(\n",
    "    search_type = 'mmr', search_kwargs = {'k':3})\n",
    "print(f\"Number of vectors stored : {vector_store1._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9aa823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
